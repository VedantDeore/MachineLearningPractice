# -*- coding: utf-8 -*-
"""Ridge, Lasso, Elastic Net Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ix5fm3qrkLIP1dfWxuU_LS7I8ropa2l3

# **About Dataset** <br>
The dataset includes **244 instances** that regroup a data of two regions of **Algeria**, namely the
Bejaia region located in the northeast of Algeria  <br>and the
 Sidi Bel-abbes  region located in the northwest of Algeria.

122 instances for each region.

The period from June 2012 to September 2012.
The dataset includes 11 attributes and 1 output attribute (class)
The 244 instances have been classified into fire (138 classes) and not fire (106 classes) classes.

Additional Variable Information
1. Date : (DD/MM/YYYY) Day, month ('june' to 'september'), year (2012)
Weather data observations
2. Temp : temperature noon (temperature max)  in Celsius degrees: 22 to 42
3. RH : Relative Humidity in %: 21 to 90
4. Ws :Wind speed in km/h: 6 to 29
5. Rain: total day in mm: 0 to 16.8
FWI Components  
6. Fine Fuel Moisture Code (FFMC) index from the FWI system: 28.6 to 92.5
7. Duff Moisture Code (DMC) index from the FWI system: 1.1 to 65.9
8. Drought Code (DC) index from the FWI system:  7 to 220.4
9. Initial Spread Index (ISI) index from the FWI system: 0 to 18.5
10. Buildup Index (BUI) index from the FWI system: 1.1 to 68
11. Fire Weather Index (FWI) Index: 0 to 31.1
12. Classes: two classes, namely Fire and Not Fire
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv("/content/Algerian_forest_fires_dataset_UPDATE.csv", header=1)

dataset.head()

dataset.info()

"""## Data Cleaning"""

## missing values
dataset.isnull().sum()

dataset.isnull().sum().sum()

dataset[dataset.isnull().any(axis =1)]

"""Add a new Column with region"""

dataset.loc[:122,["Region"]] = 0
dataset.loc[122:,["Region"]] = 1
dataset.head()

dataset.info()

dataset["Region"] = dataset["Region"].astype(int)

dataset.info()

df = dataset

df.head(-1)

df.isnull().sum()

"""## Remove NUll Values"""

df = df.dropna().reset_index(drop=True)
df.head()

df.isnull().sum()

df.iloc[[122]]

df = df.drop(index=122).reset_index(drop=True)

df.iloc[[122]]

df.columns

"""## fix spaces in column names"""

df.columns = df.columns.str.strip()

df.columns

df.info()

"""## Change the required columns as integer datatype"""

df[['month','day','year','Temperature','RH','Ws']] = df[['month','day','year','Temperature','RH','Ws']].astype(int)

df.info()

"""### Changing the other columns to float datatype"""

objects = [features for features in df.columns if df[features].dtype == 'O']
# shows which features have O as an object class

for i in objects:
  if i != 'Classes':
    df[i] = df[i].astype(float)

df.info()

df.describe()

df.head()

"""## Lets Save the Clean dataset"""

df.to_csv('Clean_Algerian_forest_fires_cleaned_dataset.csv', index= False)

"""## Exploratory Data Analysis"""

df_copy = df

df.drop(['day', 'month', 'year'], axis =1)

"""## Encoding of the categories in classes"""

df['Classes'].value_counts()

df_copy['Classes'] = np.where(df_copy['Classes'].str.contains( 'not fire'),0, 1)

df_copy.head()
df.drop('classes', axis =1, inplace= True)

df_copy['Classes'].value_counts()

## Plot density plot for all features
plt.style.use('fivethirtyeight')
df_copy.hist(figsize=(15,15))
plt.show()

## Percentage for Pie Chart
percentage = df_copy['Classes'].value_counts(normalize = True)*100

# Plotting piechart
classlabels = ['Fire', 'Not Fire']
plt.figure(figsize = (5,5))
plt.pie(percentage, labels=classlabels, autopct = '%1.1f%%' )
plt.title('Pie Chart for Classes')
plt.show()

df.corr()

## Correlation
plt.figure(figsize = (15,15))
sns.heatmap(df_copy.corr(), annot = True)
plt.show()

## Box Plots
sns.boxplot(df_copy['FWI'], color = 'green')
plt.show()

df.head()

"""## Monthly Fire Analysis"""

df.temp = [df.loc[df['Region']]== 1]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month', data=df, hue='Classes')
plt.legend(loc='upper right')
plt.ylabel('Number of fires', weight = 'bold')
plt.xlabel('Month', weight = 'bold')
plt.title('Monthly Fire Analysis of Sidi Bel Region', weight = 'bold')
plt.show()

df.temp = [df.loc[df['Region']]== 0]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month', data=df, hue='Classes')
plt.legend(loc='upper right')
plt.ylabel('Number of fires', weight = 'bold')
plt.xlabel('Month', weight = 'bold')
plt.title('Monthly Fire Analysis of Bejaya Region', weight = 'bold')
plt.show()

"""## Feature Selection"""

df.head()

df.columns

df.drop(['day', 'month', 'year'], axis =1, inplace= True)

df.head()

df['Classes'].value_counts()

"""## Independent and dependent features"""

X = df.drop('FWI', axis =1)
y = df['FWI']

X.head()

y

"""## Train Test Split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)

X_train.shape, X_test.shape

"""## Feature Selection based on correlation"""

X_train.corr()

## Check for multicolinearity
plt.figure(figsize = (15,15))
sns.heatmap(X_train.corr(), annot = True)
plt.show()

def correlation(dataset, threshold):
  col_corr = set()
  corr_matrix = dataset.corr()
  for i in range(len(corr_matrix.columns)):
    for j in range(i):
      if abs(corr_matrix.iloc[i,j]) > threshold:
        colname = corr_matrix.columns[i]
        col_corr.add(colname)
  return col_corr
# Remvove the feature that is highly correlated

# THRESHOLD -- Domain expertise
corr_features = correlation(X_train, 0.85)

## Drop features when the correlation is more than 0.85
X_train.drop(corr_features, axis =1, inplace= True)
X_test.drop(corr_features, axis =1, inplace= True)

X_train.shape, X_test.shape

"""## Feature Scaling or Standardization"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled

X_test_scaled

## Box plots to understand effect of Standard Scalar
plt.subplots(figsize=(15,5))
plt.subplot(1,2,1)
sns.boxplot(data = X_train)
plt.title('X_train Before Scalin')
plt.subplot(1,2,2)
sns.boxplot(data = X_train_scaled)
plt.title('X_train After Scaling')
plt.show()

"""## Model Training"""



"""## Linear Regression"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

lineareg = LinearRegression()
lineareg.fit(X_train_scaled, y_train)
y_pred = lineareg.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

plt.scatter(y_test, y_pred)

"""## Lasso Regression"""

from sklearn.linear_model import Lasso
lassoreg = Lasso()
lassoreg.fit(X_train_scaled, y_train)
y_pred = lassoreg.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

"""## Ridge Regression"""

from sklearn.linear_model import Ridge
ridgereg = Ridge()
ridgereg.fit(X_train_scaled, y_train)
y_pred = ridgereg.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

"""## Elastic Net Regression"""

from sklearn.linear_model import ElasticNet
elasticnetreg = ElasticNet()
elasticnetreg.fit(X_train_scaled, y_train)
y_pred = elasticnetreg.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

"""## Cross Validations"""

from sklearn.linear_model import LassoCV
# Cross Validation
# Iterative fitting along with regularisation
# by default 5 folds else we can set by cv = n
lassocv = LassoCV(cv =5)
lassocv.fit(X_train_scaled, y_train)
y_pred = lassocv.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

lassocv.alphas_

lassocv.mse_path_

from sklearn.linear_model import RidgeCV
# Cross Validation
# Iterative fitting along with regularisation
# by default 5 folds else we can set by cv = n
ridgecv = RidgeCV(cv =2)
ridgecv.fit(X_train_scaled, y_train)
y_pred = ridgecv.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

from sklearn.linear_model import ElasticNetCV
# Cross Validation
# Iterative fitting along with regularisation
# by default 5 folds else we can set by cv = n
elasticnetcv = ElasticNetCV(cv =2)
elasticnetcv.fit(X_train_scaled, y_train)
y_pred = ridgecv.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
plt.scatter(y_test, y_pred)

ridgecv.alphas

ridgecv.get_params()

